import asyncio
import time
import sys, os
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "src"))

from pydantic import BaseModel

from mcp_agent.app import MCPApp
from mcp_agent.config import (
    GoogleSettings,
    Settings,
    LoggerSettings,
    MCPSettings,
    MCPServerSettings,
)
from mcp_agent.agents.agent import Agent
from mcp_agent.workflows.llm.augmented_llm_google import GoogleAugmentedLLM


class Essay(BaseModel):
    title: str
    body: str
    conclusion: str


# å›åˆ°å°ˆæ¡ˆæ ¹ç›®éŒ„
BASE_DIR = os.path.dirname(os.path.dirname(__file__))

settings = Settings(
    execution_engine="asyncio",
    logger=LoggerSettings(type="file", level="debug"),
    mcp=MCPSettings(
        servers={
            "job_guardian": MCPServerSettings(
                command="python",
                args=[os.path.join(BASE_DIR, "mcp_server", "server.py")],
                transport="stdio",
            ),
        }
    ),
    google=GoogleSettings(default_model="gemini-2.0-flash"),
)

app = MCPApp(name="mcp_basic_agent", settings=settings)


async def example_usage():
    async with app.run() as agent_app:
        logger = agent_app.logger
        context = agent_app.context

        job_guardian_agent = Agent(
            name="job_guardian",
            instruction=(
                "You are Job Guardian, an intelligent assistant that can use three tools:\n"
                "1ï¸âƒ£ esg_hr â†’ æŸ¥è©¢å…¬å¸ ESG äººåŠ›ç™¼å±•è³‡æ–™ï¼ˆè–ªè³‡ã€ç¦åˆ©ã€å¥³æ€§ä¸»ç®¡æ¯”ä¾‹ï¼‰\n"
                "2ï¸âƒ£ labor_violations â†’ æŸ¥è©¢å‹å‹•éƒ¨é•åå‹åŸºæ³•ç´€éŒ„\n"
                "3ï¸âƒ£ ge_work_equality_violations â†’ æŸ¥è©¢é•åæ€§åˆ¥å·¥ä½œå¹³ç­‰æ³•ç´€éŒ„\n\n"
                "ç•¶ä½¿ç”¨è€…è¼¸å…¥å…¬å¸åç¨±æˆ–è‡ªç„¶èªå¥æ™‚ï¼Œæ ¹æ“šéœ€æ±‚è‡ªå‹•é¸æ“‡æ­£ç¢ºçš„ tool ä¸¦å›å‚³å°æ‡‰çµæœã€‚\n"
                "è‹¥æŸ¥è©¢å…¬å¸è³‡æ–™ï¼Œå„ªå…ˆä½¿ç”¨ esg_hrã€‚\n"
                "è‹¥æåˆ°ã€é•æ³•ã€ã€ã€ç½°é°ã€ã€ã€é•åå‹åŸºæ³•ã€ç­‰å­—çœ¼ï¼Œä½¿ç”¨ labor_violationsã€‚\n"
                "è‹¥æåˆ°ã€æ€§åˆ¥å¹³ç­‰ã€ã€ã€æ€§é¨·æ“¾ã€ã€ã€å¹³æ¬Šã€ç­‰å­—çœ¼ï¼Œä½¿ç”¨ ge_work_equality_violationsã€‚\n"
                "è‹¥æŸ¥è©¢å¥ä¸­åŒæ™‚æåˆ°ã€Œé•æ³•ã€èˆ‡ã€Œæ€§åˆ¥ã€ï¼Œè«‹å„ªå…ˆä½¿ç”¨ ge_work_equality_violationsã€‚\n"
                "è‹¥å¥å­ä¸­åƒ…æœ‰å…¬å¸åç¨±ï¼Œè«‹ä½¿ç”¨ esg_hrã€‚\n"

            ),
            server_names=["job_guardian"],
        )

        async with job_guardian_agent:
            llm = await job_guardian_agent.attach_llm(GoogleAugmentedLLM)

            # ğŸ§  è®“ä½¿ç”¨è€…è¼¸å…¥æŸ¥è©¢
            user_query = input("è«‹è¼¸å…¥æŸ¥è©¢å…§å®¹ï¼ˆå…¬å¸åç¨±æˆ–è‡ªç„¶èªå¥ï¼‰: ")

            # ğŸ’¬ äº¤çµ¦ LLM è‡ªå‹•æ±ºç­–å‘¼å« tool
            result = await llm.generate_str(
                message=f"æ ¹æ“šè¼¸å…¥å…§å®¹ã€Œ{user_query}ã€ï¼Œè«‹æŸ¥è©¢å°æ‡‰çš„å…¬å¸ç´€éŒ„ã€‚"
            )

            print("\nğŸª„ LLM è‡ªå‹•æ¨ç†çµæœï¼š")
            print(result)

            # ğŸ’¡ ä¹Ÿå¯çµæ§‹åŒ–è¼¸å‡º (optional)
            structured = await llm.generate_structured(
                message=f"æ ¹æ“šè¼¸å…¥å…§å®¹ã€Œ{user_query}ã€ï¼Œè«‹ç¸½çµé€™å®¶å…¬å¸çš„ç‹€æ³ï¼ˆä»¥ Essay æ ¼å¼å›å‚³ï¼‰ã€‚",
                response_model=Essay,
            )

            print("\nğŸ“„ çµæ§‹åŒ–è¼¸å‡ºï¼š")
            print(structured)


if __name__ == "__main__":
    start = time.time()
    asyncio.run(example_usage())
    end = time.time()
    print(f"\nTotal run time: {end - start:.2f}s")
