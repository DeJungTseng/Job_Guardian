import asyncio
import sys, os
import time
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse, PlainTextResponse
from fastapi.middleware.cors import CORSMiddleware
import uvicorn

sys.path.append(os.path.join(os.path.dirname(__file__), "..", "src"))

from pydantic import BaseModel
from mcp_agent.app import MCPApp
from mcp_agent.config import (
    GoogleSettings,
    Settings,
    LoggerSettings,
    MCPSettings,
    MCPServerSettings,
)
from mcp_agent.agents.agent import Agent
from mcp_agent.workflows.llm.augmented_llm_google import GoogleAugmentedLLM

# === Data Model ===
class Essay(BaseModel):
    title: str
    body: str
    conclusion: str


# === Global Settings ===
BASE_DIR = os.path.dirname(os.path.dirname(__file__))

settings = Settings(
    execution_engine="asyncio",
    logger=LoggerSettings(type="file", level="debug"),
    mcp=MCPSettings(
        servers={
            "job_guardian": MCPServerSettings(
                command="python",
                args=[os.path.join(BASE_DIR, "mcp_server", "server.py")],
                transport="stdio",
            ),
        }
    ),
    google=GoogleSettings(default_model="gemini-2.0-flash"),
)

# === FastAPI åˆå§‹åŒ– ===
app = FastAPI(title="Job Guardian API", version="1.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # âš ï¸ ä¸Šç·šæ™‚å¯æ”¹æˆä½ çš„ render å‰ç«¯ç¶²åŸŸ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# === Agent ç‹€æ…‹ ===
mcp_app = MCPApp(name="job_guardian_agent", settings=settings)
agent_state = {"ready": False, "agent": None, "llm": None, "logs": []}


# === å•Ÿå‹•äº‹ä»¶ ===
@app.on_event("startup")
async def startup_event():
    asyncio.create_task(start_agent())  # èƒŒæ™¯å•Ÿå‹•
    agent_state["logs"].append("ğŸš€ Agent startup task scheduled.")


async def start_agent():
    async with mcp_app.run() as agent_app:
        job_guardian_agent = Agent(
            name="job_guardian",
            instruction=(
                "You are Job Guardian, an intelligent assistant that can use three tools:\n"
                "1ï¸âƒ£ esg_hr â†’ æŸ¥è©¢å…¬å¸ ESG äººåŠ›ç™¼å±•è³‡æ–™ï¼ˆè–ªè³‡ã€ç¦åˆ©ã€å¥³æ€§ä¸»ç®¡æ¯”ä¾‹ï¼‰\n"
                "2ï¸âƒ£ labor_violations â†’ æŸ¥è©¢å‹å‹•éƒ¨é•åå‹åŸºæ³•ç´€éŒ„\n"
                "3ï¸âƒ£ ge_work_equality_violations â†’ æŸ¥è©¢é•åæ€§åˆ¥å·¥ä½œå¹³ç­‰æ³•ç´€éŒ„\n\n"
                "æ ¹æ“šä½¿ç”¨è€…è¼¸å…¥å…§å®¹ï¼ˆå…¬å¸åç¨±æˆ–è‡ªç„¶èªå¥ï¼‰è‡ªå‹•é¸æ“‡æ­£ç¢ºçš„ tool ä¸¦å›å‚³çµæœã€‚"
            ),
            server_names=["job_guardian"],
        )

        async with job_guardian_agent:
            llm = await job_guardian_agent.attach_llm(GoogleAugmentedLLM)
            agent_state.update({
                "ready": True,
                "agent": job_guardian_agent,
                "llm": llm
            })
            agent_state["logs"].append("âœ… Job Guardian agent initialized and ready.")

            # ä¿æŒå¸¸é§
            while True:
                await asyncio.sleep(60)


# === API ===
@app.get("/")
async def root():
    return {"status": "running", "agent_ready": agent_state["ready"]}


@app.get("/logs")
async def logs():
    """é¡¯ç¤º agent ç‹€æ…‹ï¼ˆçµ¦ telemetry iframe ç”¨ï¼‰"""
    return PlainTextResponse("\n".join(agent_state["logs"][-50:]))


@app.post("/query")
async def query(request: Request):
    """Assistant-UI å‘¼å«çš„ä¸»è¦ API"""
    if not agent_state["ready"]:
        return JSONResponse({"error": "Agent å°šæœªåˆå§‹åŒ–å®Œæˆ"}, status_code=503)

    data = await request.json()
    user_query = data.get("query", "").strip()
    if not user_query:
        return JSONResponse({"error": "è«‹è¼¸å…¥æŸ¥è©¢å…§å®¹"}, status_code=400)

    llm = agent_state["llm"]
    start = time.time()

    try:
        # 1ï¸âƒ£ LLM åˆ¤æ–·æ‡‰ç”¨çš„ tool ä¸¦æŸ¥è©¢
        result = await llm.generate_str(
            message=f"æ ¹æ“šè¼¸å…¥å…§å®¹ã€Œ{user_query}ã€ï¼Œè«‹æŸ¥è©¢å°æ‡‰çš„å…¬å¸ç´€éŒ„ã€‚"
        )

        # 2ï¸âƒ£ ç”Ÿæˆçµæ§‹åŒ–æ‘˜è¦
        structured = await llm.generate_structured(
            message=f"æ ¹æ“šè¼¸å…¥å…§å®¹ã€Œ{user_query}ã€ï¼Œè«‹ç¸½çµé€™å®¶å…¬å¸çš„ç‹€æ³ï¼ˆä»¥ Essay æ ¼å¼å›å‚³ï¼‰ã€‚",
            response_model=Essay,
        )

        elapsed = time.time() - start
        msg = f"âœ… æŸ¥è©¢å®Œæˆ ({elapsed:.2f}s)ï¼š{user_query}"
        agent_state["logs"].append(msg)

        return {
            "query": user_query,
            "result": result,
            "structured": structured.model_dump(),
            "elapsed": elapsed,
        }

    except Exception as e:
        err_msg = f"âŒ æŸ¥è©¢å¤±æ•—: {e}"
        agent_state["logs"].append(err_msg)
        return JSONResponse({"error": str(e)}, status_code=500)


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=int(os.getenv("PORT", 8000)))
